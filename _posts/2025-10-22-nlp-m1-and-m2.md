---
layout: post
title: "NLP Modules 1 and 2"
date: 2025-10-22
categories: [OMSCS, NLP]
tags: [Natural Language Processing, Machine Learning, Statistics]
description: Modules 1 and 2 of CS 7650 - Natural Language Processing @ Georgia Tech. 
math: true
---

## M1: Intro to NLP
---


## What is Natural Language Processing? 

**Natural Language Processing (NLP)** refers to a set of computational methods, techniques, or algorithms for making human language accessible to computers. This often implies *analysis of text* or *generation of fluent, meaningful, and context appropriate text*. 

#### Natural Language

Okay, so what even is natural language? **Natural language** refers to the structured set of communication that has naturally evolved in humans through use and repetition. Separate systems (languages) have emerged, each with their own set of rules that might not be strictly defined or enforced. 

- *Syntax*: rules for composing words together. 
- *Semantics*: the meaning of the composition of words. 

#### Non-Natural Language

Conversely, a **non-natural language** is a deliberately planned and defined language. These include programming languages (Python, C++, etc.). Non-natural languages have well-defined rules of composition, and syntax structured to eliminate any kind of ambiguity. 

## What are the Goals of NLP? 

NLP can be utilized to *better facilitate human-computer interaction*. If the computer is able to understand and process natural language, it allows the human to avoid learning the computer's non-natural language. Example applications include conversational agents and writing assistance. 

Additionally, NLP can help to *process large volumes of data*. The vast majority of recorded data is stored in natural language. NLP can help with applications such as detecting patterns in text from social media, knowledge discovery from academic research, and document retrieval. 

## Why is NLP Difficult? 

What makes natural language processing so difficult for computers? There are many, many reasons: 

- Words can have multiple meanings, often depending on the domain or context. 
- Furthermore, words can be composed in different ways to have different meanings.
- Metaphors are not literal. 
- New words emerge, especially via slang / popular vocabulary. 

One key idea is that natural language has ample *syntactic ambiguity* - the same set of words can have different meanings depending on the context. Certain phrases may have intended connotations and interpretations that are more preferred over others. 

## What Fields are Involved in NLP?

First, much of NLP is based in *linguistics* and *speech*. These fields provide us with important context on language construction and patterns, which are certainly useful when building language-based models. 

NLP falls within the realm of **Artificial Intelligence (AI)**, which is a field concerned with building and understanding "machines that can compute how to act effectively and safely in a wide variety of novel situations" (Russell & Norvig, 2020). A significant portion of AI is **Machine Learning (ML)** - "the study of computer algorithms that improve automatically through experience" (Mitchell, 1997). Many NLP approaches use *Deep Learning* techniques, where deep learning refers to a class of machine learning algorithms built on deep chains of differentiable modules (e.g., neural networks). 

Finally, NLP is heavily reliant on **Statistics**. Consider an NLP classification problem - what is the probability that a movie review is positive?  

$$P(\text{Review} = + ~ | ~ w_1, \ldots,  w_n)$$  

Similarly, text generation involves probability. What is the probability that the next word should come next, given the words we have already observed?  

$$P(w_n|w_1, w_2, ..., w_{n-1})$$  



## M2: Foundations 
--- 


### Probability and Statistics

#### Basics of Probability

The fundamental unit of probability is a **random variable** - a variable that can hold a numeric value from a predefined range. A random variable has not yet been observed; conversely, an *observation* is an instance of a random variable that has been realized.   

$$ Random~Variable: X \rightarrow N(0, 1) $$  

$$ Observation: x = 0.5 $$  

Random variables have a *probability distribution* over the *sample space* - that is, each possible value of the random variable has some probability of occurring. We denote the probability of a specific value occurring as follows:   

$$P(RAIN = True) = 0.6$$  

Additionally, we can use *logical operators* to construct more complicated expressions.   

$$P(RAIN = True ~ and ~ HOT = FALSE)$$  

There are certain **rules of probability** involving logical operations: 

- *Addition Rule*: $P(A ~ or ~ B) = P(A) + P(B) - P(A \cap B)$
- *Multiplication (Product) Rule*: $P(A ~ and ~ B) = P(A) * P(B \| A)$

When dealing with multiple random variables, we should specify a **joint distribution** - this specifies the probability of two or more variables happening at the same time. Variables can impact each other - the value of one random variable may influence the value of another. A **conditional probability** represents the probability of observing a value of one variable, given that we have observed a certain value for another variable. The variable being conditioned on (and its value) are often referred to as the *evidence* term. 
$$P(A=a | B=b) = \frac{P(A \cap B)}{P(B=b)}$$
Note that in the case of two *independent* random variables, the conditional probability is equivalent to the marginal probability. 
$$Independent ~ iff ~ P(A=a) = P(A=a|B=b)$$
Our conditional probability doesn't always reference all variables in the full joint distribution - this means we have a *partial joint distribution* with some amount of *hidden variables*. We don't know the values of our hidden values, so we must consider (sum over) all possible values.
#### Bayesian Statistics 

**Bayes Rule** is a probability theorem which inverts the conditional probabilities of two random variables. Bayes Rule provides a mathematical framework to update our beliefs given some evidence. More specifically...
$$ P(B|A) = \frac{P(A|B) * P(B)}{P(A)}$$
- *Posterior Probability* $P(B\|A)$ -> updated probability of B after considering evidence. 
- *Likelihood* $P(A\|B)$ -> probability of evidence given belief is true. 
- *Prior* $P(B)$ -> probability before evidence was considered. 
- *Evidence* $P(A)$ -> probability of observing the evidence under any circumstances. 

With two random variables, Bayes Rule is straightforward; with multiple random variables, we can extend the formula to fit our case. 
$$P(B|A_1, A_2) = \frac{P(A_2|B, A_1) * P(B, A_1)}{P(A_1, A_2)}$$
- remember via the product rule that $P(B, A_1) = P(A_1\|B) * P(B)$

One example application of Bayes Rule is for cause-and-effect analysis - we may have one thing that is relatively easy to observe (effect), and something else we would like to estimate that is not as easy to observe (cause). If we have multiple independent effect variables, we have the following mathematical relationship (where alpha is the normalization term). 
$$P(C|E_1, E_2, ..., E_n) = \alpha P(E_1|C) P(E_2|C) ... P(E_n|C)$$
The **NaÃ¯ve Bayes Assumption** assumes that effects are independent, enabling this calculation. 

A **Bayesian Network** is the same thing as Bayes Rule applied to multiple random variables, but instead represented as a *directed acyclic graph (DAG)* of *nodes*. More formally, a Bayesian Network is a method for visualizing the causal relationship between random variables. 
#### Application to Language + NLP

In NLP, we run into the situation of a Bayesian framework all the time. Consider the following example: what is the probability of a positive review sentiment given the observed words? 
$$P(S = + ~ \| ~ w_1, w_2, ~ ..., w_n) = \alpha P(S = +) * \prod{P(w_i ~ \| ~ S=+)}$$
Documents are *probabilistic word emissions* - the document is of a certain class (ex: sentiment = positive), and it emits words in a probabilistic fashion, conditioned on the document class. 

### Machine Learning
#### Supervised Learning

**Supervised Learning** is a class of machine learning algorithms dedicated to to predicting some output from an input; in other words, supervised learning is a form of *function approximation* where the goal is to learn a *target function* mapping inputs (X) to outputs (y). 
$$ f : X \rightarrow y$$
A predictive model is fit on *training data* of the form $(X_i, y_i)$, with performance measured via some *objective function*. Supervised learning tasks may be broadly grouped into two problem types: 

- *Classification* -> output variable is discrete / categorical. 
- *Regression* -> output variable is continuous / numeric. 
#### Neural Networks 

A **Neural Network** is an artificial mathematical model used to approximate *non-linear functions*. Neural networks are one approach to supervised learning, but are also used in other subfields of machine learning (unsupervised, reinforcement learning). 

Neural networks contain dense interconnected *layers* of *nodes*. Each node is a simple gated function, where gating is controlled via a *linear combination* of features and weights, and some *activation function* to process the linear combination. 

**Gradient Descent** is the primary algorithm used to *optimize* - calculate the optimal weights - for a neural network. Gradient descent relies on some **loss function** to measure a neural network's performance on predictions. For example, *mean squared error* is calculated as follows: 
$$MSE = \frac{\Sigma(y_i - \hat{y_i})^2}{N}$$
The optimal weights for a neural network should minimize the loss function. This is a calculus (optimization) problem - we need to calculate the **gradient**, which is the *vector of partial derivatives* of the loss function with respect to each weight. 
$$\nabla L = [\frac{\partial_L}{\partial_{w_1}}, \frac{\partial_L}{\partial_{w_2}}, ..., \frac{\partial_L}{\partial_{w_n}}]$$
The gradient points in the direction of steepest ascent. Therefore, if we were to change each weight by its corresponding partial derivative, we would proceed in the direction of most increasing loss. Instead, for gradient descent, we are interested in proceeding in the direction of *steepest descent* to reduce loss in the most efficient manner. Gradient descent is an *iterative* algorithm; here is a single update / step in gradient descent: 
$$w_{k+1} = w_k + \eta \nabla L(w)$$
- $k$ represents the current step of training. 
- $\eta$ is the learning rate, and controls step size (how large of a change we induce in weights during a given step). 
#### Deep Learning

**Deep learning** refers to a specific class of machine learning models composed of many (e.g., a deep number of) individual *modules* / layers of differentiable parameters. Deep learning is most commonly applied with neural networks using a large number of layers and activation functions. 

### Programming
#### Modern Deep Learning Libraries

The primary modern software libraries for implementing deep learning include **PyTorch**, **TensorFlow**, and **Keras**. Each of these libraries are able to use *parallelization* to increase the computational efficiency of gradient descent, via integration with the *graphics processing unit (GPU)*. In this class, we will focus on PyTorch. 

PyTorch uses *tensors* as the fundamental data structure, where a tensor is an n-dimensional array of values (generalization of scalar / vector / matrix to higher dimensions). We can create a model in PyTorch by subclassing the `torch.nn.module` class. 


```python

from torch import nn

class MyNeuralNetwork(nn.Module): 

	def __init__(self): 
		
		""" self is where we define the architecture of our NN via layers.
		"""
		
		## call the superclass (nn.Module) to initialize our subclass 
		super().__init__()
		
		## flatten input data into a 1D vector (for input to neural network)
		self.flatten = nn.Flatten() 
		
		## construct neural network 
		self.model = nn.Sequential([
			nn.Linear(5, 3),   ## each layer takes n_input, n_output as params	
			nn.Sigmoid(), 
			nn.Linear(3, 5), 
			nn.Sigmoid(), 
			nn.Linear(5, 1), 
			nn.Sigmoid()
		])
		
	def forward(self, x): 
	
		""" forward is where we define how an input is transformed by our model.
		"""
		
		x = self.flatten(x) 
		y = self.model(x) 
		
		return y
		
		
## instantiate model + predict on instance
model = MyNeuralNetwork() 
pred = model(x) 

```


